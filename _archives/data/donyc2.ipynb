{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date)\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "queried_past_date_df\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_future_date_df\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    venue_dates_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "    queried_past_date_df = venue_dates_df[venue_dates_df['date'] < queried_current_date][::-1]\n",
    "    queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "    queried_future_date_df = venue_dates_df[venue_dates_df['date'] >= queried_current_date]\n",
    "\n",
    "# TODO use queried_past_date_df as foundation and iterate through pages from past_base_url, and for each page find \"event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\"\"\n",
    "# TODO Create a indexed_date field set to queried_current_date\n",
    "# TODO create a event_count field set to 0\n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, output queried_past_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n",
    "# TODO use queried_future_date_df as foundation and iterate through pages from future_base_url, and for each page find \"event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\"\"\n",
    "# TODO Create a indexed_date field set to queried_current_date\n",
    "# TODO create a event_count field set to 0\n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, output queried_future_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date)\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "queried_past_date_df\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_future_date_df\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    venue_dates_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "    queried_past_date_df = venue_dates_df[venue_dates_df['date'] < queried_current_date][::-1]\n",
    "    queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "    queried_future_date_df = venue_dates_df[venue_dates_df['date'] >= queried_current_date]\n",
    "\n",
    "# TODO use queried_past_date_df as foundation and iterate through pages from past_base_url, and for each page find \"event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\"\"\n",
    "# TODO Create a indexed_date field set to queried_current_date\n",
    "# TODO create a event_count field set to 0\n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, output queried_past_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n",
    "# TODO use queried_future_date_df as foundation and iterate through pages from future_base_url, and for each page find \"event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\"\"\n",
    "# TODO Create a indexed_date field set to queried_current_date\n",
    "# TODO create a event_count field set to 0\n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, output queried_future_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date)\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "queried_past_date_df\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_future_date_df\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    venue_dates_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "    queried_past_date_df = venue_dates_df[venue_dates_df['date'] < queried_current_date][::-1]\n",
    "    queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "    queried_future_date_df = venue_dates_df[venue_dates_df['date'] >= queried_current_date]\n",
    "\n",
    "# TODO iterate through every i, row of queried_past_date_df and from there retrieve year = date.year, month and day from date = row['date']\n",
    "# TODO create a count field set to 0\n",
    "# TODO set page_num = 1 and continue_for = False\n",
    "# TODO while true:\n",
    "# TODO  url = past_base_url.format(QUERIED_TEXT, page_num)\n",
    "# TODO  response = requests.get(url)\n",
    "# TODO  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# TODO  event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "# TODO  if not event_cards:\n",
    "# TODO   break\n",
    "# TODO  for card in event_cards:\n",
    "# TODO   anchor = card.find('a', href=lambda href: href and href.startswith('/events/{}/{}/{}/'.format(year, month, day)), class_='ds-listing-event-title url summary')\n",
    "# TODO   if anchor:\n",
    "# TODO    count += 1\n",
    "# TODO   else:\n",
    "# TODO    continue_for = True\n",
    "# TODO    break\n",
    "# TODO  print(page_num)\n",
    "# TODO  page_num += 1\n",
    "# TODO  if continue_for:\n",
    "# TODO   break\n",
    "# TODO \n",
    "# TODO \n",
    "# TODO \n",
    "# TODO \n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, append queried_future_date_df to queried_past_date_df into all_queried_date_df and run all_queried_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n",
    "# TODO use queried_future_date_df as foundation and iterate through pages from future_base_url, and for each page find \"event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\"\"\n",
    "# TODO Create a nindexed_date field set to queried_current_date\n",
    "# TODO create a count field set to 0\n",
    "# TODO From the event tag's href, parse \"events/{year}/{month}/{day}/\" of the event\n",
    "# TODO if the parse date is same from indexed_date, increment event_count by 1\n",
    "# TODO if the parse date is different from indexed_date, append queried_future_date_df to queried_past_date_df into all_queried_date_df and run all_queried_date_df.to_csv(csv_filename, index=False) and set indexed_date to the event's date and set variable event_count to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date - timedelta(days=1))\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "queried_past_date_df\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'total_{QUERIED_TEXT}_events'] = None\n",
    "queried_future_date_df\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    venue_dates_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "    queried_past_date_df = venue_dates_df[venue_dates_df['date'].dt.date < queried_current_date][::-1]\n",
    "    # queried_past_date_df = venue_dates_df[venue_dates_df['date'] < queried_current_date].sort_values('date', ascending=False)\n",
    "    queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "    queried_future_date_df = venue_dates_df[venue_dates_df['date'].dt.date >= queried_current_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://donyc.com/venues/madison-square-garden/past_events?page=1\n",
      "2023-03-02\n",
      "2023-03-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjong\\AppData\\Local\\Temp\\ipykernel_28264\\4102906405.py:36: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  if event_date < queried_start_date:\n",
      "C:\\Users\\cjong\\AppData\\Local\\Temp\\ipykernel_28264\\4102906405.py:40: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  queried_past_date_df.loc[queried_past_date_df['date'] == event_date, 'date'] = 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28264\\4102906405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mevent_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueried_future_date_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogic_complete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6921\u001b[0m                 \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6923\u001b[1;33m             indexer = nargsort(\n\u001b[0m\u001b[0;32m   6924\u001b[0m                 \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6925\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[1;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mnon_nans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mnon_nan_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare indexing variables\n",
    "page_num = 1\n",
    "logic_complete = False\n",
    "\n",
    "\n",
    "# Reminder, in the past loop, the \"newer\"Dates in code have lower date values\n",
    "while True:\n",
    "    # Set key to complete loop\n",
    "\n",
    "        # if increment_date:\n",
    "    # # Set date info\n",
    "    # _date = queried_past_date_df.loc[queried_past_date_df_index, 'date']\n",
    "    # year = _date.year\n",
    "    # month = _date.month\n",
    "    # day = _date.day\n",
    "        # reset_date = False\n",
    "\n",
    "        # if increment_url:\n",
    "    # Set card info\n",
    "    url = past_base_url.format(QUERIED_TEXT, page_num)\n",
    "    print(f'{url}')\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "        # reset_url = False\n",
    "\n",
    "        # While True, loop through every event_cards\n",
    "        # while True:\n",
    "\n",
    "    for card in event_cards:\n",
    "        href = card.find('a')['href']\n",
    "        year, month, day = [int(x) for x in href.split('/')[2:5] if x.isdigit()]\n",
    "        event_date = date(year, month, day)\n",
    "        print(event_date)\n",
    "        \n",
    "        if event_date.date() < queried_start_date:\n",
    "            logic_complete = True\n",
    "            break\n",
    "\n",
    "        queried_past_date_df.loc[queried_past_date_df['date'] == event_date, 'date'] = 1\n",
    "        pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "        \n",
    "    if logic_complete:\n",
    "        break\n",
    "\n",
    "    # one page is complete, run the next page\n",
    "    print(page_num)\n",
    "    page_num += 1\n",
    "\n",
    "    #     print(f'card date {event_date}')\n",
    "    #     print(f'{_date} of count {count}')\n",
    "\n",
    "    #     # If the newest card date value is lower than queried_start_date then initiate emergency brakes\n",
    "    #     if event_date < queried_start_date.date():\n",
    "    #         logic_complete = True\n",
    "    #         break\n",
    "\n",
    "    #     if event_date < _date.date():\n",
    "    #         if not _date == queried_current_date:\n",
    "    #             while event_date < _date.date():\n",
    "                    \n",
    "    #                 queried_past_date_df_index += 1\n",
    "    #                 count = 0\n",
    "    #                 _date = queried_past_date_df.loc[queried_past_date_df_index, 'date']\n",
    "                    \n",
    "    #                 if event_date == _date.date():\n",
    "    #                     count += 1\n",
    "\n",
    "    #     # # If event_date matches index date, then increment count\n",
    "    #     # if event_date == _date.date():\n",
    "    #     #     count += 1\n",
    "    \n",
    "    #     # # If event_date is less than index date, add a new count entry for _date and move on\n",
    "    #     # elif event_date < _date.date():\n",
    "    #     #     queried_past_date_df.loc[queried_past_date_df_index, f'total_{QUERIED_TEXT}_events'] = count\n",
    "    #     #     # While inefficient to sort every time, it allows for pause and resumption of downloads effortlessly\n",
    "    #     #     pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "\n",
    "    #     #     while event_date < _date.date():\n",
    "                \n",
    "    #     #         queried_past_date_df_index += 1\n",
    "    #     #         count = 0\n",
    "    #     #         _date = queried_past_date_df.loc[queried_past_date_df_index, 'date']\n",
    "                \n",
    "    #     #         if event_date == _date.date():\n",
    "    #     #             count += 1\n",
    "\n",
    "    #         # queried_past_date_df.loc[queried_past_date_df_index, f'total_{QUERIED_TEXT}_events'] = count\n",
    "\n",
    "    #         # # While inefficient to sort every time, it allows for pause and resumption of downloads effortlessly\n",
    "    #         # pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "            \n",
    "    #         # queried_past_date_df_index += 1\n",
    "    #         # count = 0\n",
    "\n",
    "    #         # _date = queried_past_date_df.loc[queried_past_date_df_index, 'date']\n",
    "            \n",
    "    #         # if event_date == _date.date():\n",
    "    #         #     count += 1\n",
    "\n",
    "    #     # # If event_date is greater than index date, add a new 0 entry for _date and move on\n",
    "    #     # elif event_date > _date.date():\n",
    "    #     #     queried_past_date_df.loc[queried_past_date_df_index, f'total_{QUERIED_TEXT}_events'] = count\n",
    "            \n",
    "    #     #     # While inefficient to sort every time, it allows for pause and resumption of downloads effortlessly\n",
    "    #     #     pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "            \n",
    "    #     #     queried_past_date_df_index += 1\n",
    "    #     #     count = 0\n",
    "\n",
    "    #     #     _date = queried_past_date_df.loc[queried_past_date_df_index, 'date']\n",
    "\n",
    "    # if logic_complete:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://donyc.com/venues/madison-square-garden/past_events?page=1\n",
      "2023-03-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjong\\AppData\\Local\\Temp\\ipykernel_28264\\2674046366.py:58: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  if event_date < queried_start_date.date():\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Timestamp' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28264\\2674046366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mevent_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueried_past_date_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueried_future_date_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogic_complete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6921\u001b[0m                 \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6923\u001b[1;33m             indexer = nargsort(\n\u001b[0m\u001b[0;32m   6924\u001b[0m                 \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6925\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\cjong\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[1;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mnon_nans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mnon_nan_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Timestamp' and 'int'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date - timedelta(days=1))\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'{QUERIED_TEXT}_event_ocurred'] = 0\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "queried_past_date_df\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'{QUERIED_TEXT}_event_ocurred'] = 0\n",
    "queried_future_date_df\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    venue_dates_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "    queried_past_date_df = venue_dates_df[venue_dates_df['date'].dt.date < queried_current_date][::-1]\n",
    "    # queried_past_date_df = venue_dates_df[venue_dates_df['date'] < queried_current_date].sort_values('date', ascending=False)\n",
    "    queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "    queried_future_date_df = venue_dates_df[venue_dates_df['date'].dt.date >= queried_current_date]\n",
    "\n",
    "# Prepare indexing variables\n",
    "page_num = 1\n",
    "logic_complete = False\n",
    "\n",
    "\n",
    "# Reminder, in the past loop, the \"newer\"Dates in code have lower date values\n",
    "while True:\n",
    "    url = past_base_url.format(QUERIED_TEXT, page_num)\n",
    "    print(f'{url}')\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "\n",
    "    for card in event_cards:\n",
    "        href = card.find('a')['href']\n",
    "        year, month, day = [int(x) for x in href.split('/')[2:5] if x.isdigit()]\n",
    "        event_date =  pd.to_datetime(date(year, month, day))\n",
    "        # event_date =  pd.to_datetime(f'{year}-{month}-{day}')\n",
    "        \n",
    "        if event_date < queried_start_date.date():\n",
    "            logic_complete = True\n",
    "            break\n",
    "\n",
    "        queried_past_date_df.loc[queried_past_date_df['date'] == event_date, 'date'] = 1\n",
    "        pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "        \n",
    "    if logic_complete:\n",
    "        break\n",
    "\n",
    "    # one page is complete, run the next page\n",
    "    print(page_num)\n",
    "    page_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8b887db99f8edfa7f3e3a008cc1b31fa63afeb09acb3c9f070418078094f7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
