{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "QUERIED_TEXT = 'events'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01') #, format='%Y%m%d')\n",
    "queried_end_date = pd.to_datetime('2023-06-01') #, format='%Y%m%d')\n",
    "queried_date_range = pd.date_range(start=queried_start_date, end=queried_end_date)\n",
    "queried_date_range_df = pd.DataFrame({'date': queried_date_range})\n",
    "queried_date_range_df[f'total_{QUERIED_TEXT}'] = None\n",
    "\n",
    "# Set the base URL\n",
    "base_url = 'https://donyc.com/events/{}/{}/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    queried_date_range_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "\n",
    "# Loop through each date in the date range\n",
    "for i, row in queried_date_range_df.iterrows():\n",
    "\n",
    "    date = row['date']\n",
    "\n",
    "    # Check if the 'total_{QUERIED_TEXT}' column is not NaN, if yes then break out of the loop\n",
    "    if not pd.isna(row[f'total_{QUERIED_TEXT}']):\n",
    "        print(f'{date} is already populated')\n",
    "        continue\n",
    "\n",
    "    # Format the URL with the year, month, day, and page number\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    page_num = 1\n",
    "\n",
    "    # Initialize the count to 0\n",
    "    count = 0\n",
    "\n",
    "    # Loop through each page of {QUERIED_TEXT} for the current date\n",
    "    while True:\n",
    "        # Make a request to the current page\n",
    "        url = base_url.format(year, month, day, page_num)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all div elements with a class attribute starting with 'ds-listing event-card'\n",
    "        event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "\n",
    "        # If no event cards are found, break out of the loop\n",
    "        if not event_cards:\n",
    "            break\n",
    "\n",
    "        # Loop through each event card that matches the specified classes\n",
    "        for card in event_cards:\n",
    "            # Find the anchor tag with an href attribute that starts with '/{QUERIED_TEXT}/2023/3/1' and the specified classes\n",
    "            anchor = card.find('a', href=lambda href: href and href.startswith('/events/{}/{}/{}'.format(year, month, day)), class_='ds-listing-event-title url summary')\n",
    "            if anchor:\n",
    "                count += 1\n",
    "\n",
    "        # Increment the page number and update the URL\n",
    "        print(page_num)\n",
    "        page_num += 1\n",
    "\n",
    "    # Set the count for the current date in the 'total_{QUERIED_TEXT}' column of the DataFrame\n",
    "    queried_date_range_df.loc[i, f'total_{QUERIED_TEXT}'] = count\n",
    "    queried_date_range_df.to_csv(csv_filename, index=False)\n",
    "    print(queried_date_range_df.loc[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music\n",
    "\n",
    "### QUERIED_TEXT can be updated to comedy, film-screenings, default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "QUERIED_TEXT = 'music'\n",
    "\n",
    "# Prepare dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01')\n",
    "queried_end_date = pd.to_datetime('2023-06-01')\n",
    "queried_date_range = pd.date_range(start=queried_start_date, end=queried_end_date)\n",
    "queried_date_range_df = pd.DataFrame({'date': queried_date_range})\n",
    "queried_date_range_df[f'total_{QUERIED_TEXT}'] = None\n",
    "\n",
    "# Set the base URL\n",
    "base_url = 'https://donyc.com/events/{}/{}/{}/{}?page={}'\n",
    "\n",
    "# Verify that file exists\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "if os.path.isfile(csv_filename):\n",
    "    queried_date_range_df = pd.read_csv(csv_filename, parse_dates=['date'])\n",
    "\n",
    "# Loop through each date in the date range\n",
    "for i, row in queried_date_range_df.iterrows():\n",
    "\n",
    "    continue_for = False\n",
    "\n",
    "    date = row['date']\n",
    "\n",
    "    # Check if the 'total_{QUERIED_TEXT}' column is not NaN, if yes then break out of the loop\n",
    "    if not pd.isna(row[f'total_{QUERIED_TEXT}']):\n",
    "        print(f'{date} is already populated')\n",
    "        continue\n",
    "\n",
    "    # Format the URL with the year, month, day, and page number\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    page_num = 1\n",
    "\n",
    "    # Initialize the count to 0\n",
    "    count = 0\n",
    "\n",
    "    # Loop through each page of {QUERIED_TEXT} for the current date\n",
    "    while True:\n",
    "\n",
    "        url = base_url.format(QUERIED_TEXT, year, month, day, page_num)\n",
    "\n",
    "        # Make a request to the current page\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all div elements with a class attribute starting with 'ds-listing event-card'\n",
    "        event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "\n",
    "        # If no event cards are found, break out of the loop\n",
    "        if not event_cards:\n",
    "            break\n",
    "\n",
    "        # Loop through each event card that matches the specified classes\n",
    "        for card in event_cards:\n",
    "            # Find the anchor tag with an href attribute that starts with '/events/{}/{}/{}/' and the specified classes\n",
    "            anchor = card.find('a', href=lambda href: href and href.startswith('/events/{}/{}/{}/'.format(year, month, day)), class_='ds-listing-event-title url summary')\n",
    "            if anchor:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue_for = True\n",
    "                break\n",
    "\n",
    "        # Increment the page number and update the URL\n",
    "        print(page_num)\n",
    "        page_num += 1\n",
    "\n",
    "        if continue_for:\n",
    "            break\n",
    "\n",
    "    # Set the count for the current date in the 'total_{QUERIED_TEXT}' column of the DataFrame\n",
    "    queried_date_range_df.loc[i, f'total_{QUERIED_TEXT}'] = count\n",
    "    queried_date_range_df.to_csv(csv_filename, index=False)\n",
    "    print(queried_date_range_df.loc[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madison Square Garden Scraper\n",
    "### QUERIED_TEXT = 'madison-square-garden' can be changed with other venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "\n",
    "QUERIED_TEXT = 'madison-square-garden'\n",
    "csv_filename = f'donyc_{QUERIED_TEXT}.csv'\n",
    "\n",
    "# Prep dataframe for all applicable date ranges for which there will be total_{QUERIED_TEXT} count\n",
    "queried_start_date = pd.to_datetime('2020-01-01')\n",
    "queried_current_date = date.today()\n",
    "queried_end_date = pd.to_datetime('2023-06-01')\n",
    "\n",
    "queried_past_date_range = pd.date_range(start=queried_start_date, end=queried_current_date - timedelta(days=1))\n",
    "queried_past_date_df = pd.DataFrame({'date': queried_past_date_range})\n",
    "queried_past_date_df[f'{QUERIED_TEXT}_event_occurred'] = 0\n",
    "queried_past_date_df = queried_past_date_df[::-1]\n",
    "queried_past_date_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "queried_future_date_range = pd.date_range(start=queried_current_date, end=queried_end_date)\n",
    "queried_future_date_df = pd.DataFrame({'date': queried_future_date_range})\n",
    "queried_future_date_df[f'{QUERIED_TEXT}_event_occurred'] = 0\n",
    "\n",
    "# Set the base URL\n",
    "past_base_url = 'https://donyc.com/venues/{}/past_events?page={}'\n",
    "future_base_url = 'https://donyc.com/venues/{}?page={}'\n",
    "\n",
    "# Reminder, in the past loop, the \"newer\" Dates in code have lower date values\n",
    "page_num = 1\n",
    "logic_complete = False\n",
    "while True:\n",
    "    url = past_base_url.format(QUERIED_TEXT, page_num)\n",
    "    print(f'{url}')\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "\n",
    "    for card in event_cards:\n",
    "        href = card.find('a')['href']\n",
    "        year, month, day = [int(x) for x in href.split('/')[2:5] if x.isdigit()]\n",
    "        event_date = pd.to_datetime(date(year, month, day))\n",
    "        print(event_date)\n",
    "\n",
    "        if event_date < queried_start_date.date():\n",
    "            logic_complete = True\n",
    "            break\n",
    "\n",
    "        queried_past_date_df.loc[queried_past_date_df['date'] == event_date, f'{QUERIED_TEXT}_event_occurred'] = 1\n",
    "        pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "\n",
    "    if logic_complete:\n",
    "        break\n",
    "\n",
    "    # one page is complete, run the next page\n",
    "    print(page_num)\n",
    "    page_num += 1\n",
    "\n",
    "# Reminder, in the future loop, the \"newer\" Dates in code have higher date values\n",
    "page_num = 1\n",
    "logic_complete = False\n",
    "while True:\n",
    "    url = future_base_url.format(QUERIED_TEXT, page_num)\n",
    "    print(f'{url}')\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    event_cards = soup.select('div[class^=\"ds-listing event-card\"]')\n",
    "\n",
    "    for card in event_cards:\n",
    "        href = card.find('a')['href']\n",
    "        year, month, day = [int(x) for x in href.split('/')[2:5] if x.isdigit()]\n",
    "        event_date = pd.to_datetime(date(year, month, day))\n",
    "        print(event_date)\n",
    "        \n",
    "        if event_date > queried_end_date.date():\n",
    "            logic_complete = True\n",
    "            break\n",
    "\n",
    "        queried_future_date_df.loc[queried_future_date_df['date'] == event_date, f'{QUERIED_TEXT}_event_occurred'] = 1\n",
    "        pd.concat([queried_past_date_df, queried_future_date_df]).sort_values('date', ascending=True).to_csv(csv_filename, index=False)\n",
    "\n",
    "    if logic_complete:\n",
    "        break\n",
    "\n",
    "    # one page is complete, run the next page\n",
    "    print(page_num)\n",
    "    page_num += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8b887db99f8edfa7f3e3a008cc1b31fa63afeb09acb3c9f070418078094f7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
